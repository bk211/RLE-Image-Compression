\documentclass[12pt, letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{fancyvrb}

\title{Rapport de projet : Compression d'image par la méthode Run-Length-Encoding}
\author{Chaolei Cai
\\
    \multicolumn{1}{
        p{.7\textwidth}}{\centering\emph{Université Paris Vincennes St-Denis\\
  UFR mathématiques, informatique, technologies sciences de l'information\\}
  L3 Informatique}
}
\date{\today}
\begin{document}


\begin{titlepage}
    \maketitle
\end{titlepage}

\tableofcontents

\section{Présentation du projet}
Ce document est mon rapport pour le projet 11 du cours d'algorithmique avancé enseigné par M.Bourdin.\\
Le sujet de mon projet est de mettre en place l'algorithme de Run-Length-Encoding (RLE).\\
Il est demandé de satisfaire ces points suivants.
\begin{itemize}
    \item Tester le RLE à partir des trois plans R, puis G, puis B. 
    \item Tester le RLE en ayant transformé l'image en mode HSV et en séparant les champs de H, de S et de V. 
    \item Écrire dans chaque cas la fonction qui code en mode RLE, la fonction qui fait la sauvegarde et la fonction qui permet d'afficher une image ainsi sauvegardée. 
    \item Essayer votre méthode sur un bon nombre d'images et comparer les résultats obtenus, en particulier par rapport à des méthodes concurrentes (LZW...).
\end{itemize}
Le projet est disponible sur mon entrepôt GitHub via le lien suivant:\\
\url{https://github.com/bk211/RLE-Image-Compression}

\section{Dépendances, compilation et exécution du programme}
\subsection{Dépendances}
Le programme seul ne devrait que nécessiter des library "GL/glut.h" et "GL/glu.h", 
Sur un environnement Windows ou Mac, il faudra eventuellement modifier l'inclusion de ces 2 headers.\\
Il est recommandé de disposer de l'outils make et doxygen afin d'utiliser le Makefile et d'avoir accès à la documentation.\\
Le projet a été developpé sous OS Archlinux, Kernel: Linux 5.5.11-arch1-1, Architecture: x86-64\\
Si vous sur un environnement Debian, le projet de devrait pas rencontrer de problème de dépendances.

\subsection{Compilation}
Pour compiler le projet, une simple commande \$make suffit.

\subsection{Execution}
Pour exécuter le projet, plusieurs options sont à votre diposition
\begin{itemize}
    \item \$make run, lanceras l'exécutable sur l'image morty.ppm du dossier img/.
    \item \$./exec XXX, où XXX est le chemin relative vers l'image ppm à ouvrir.
    \item \$make run FILE=XXX, où XXX est le chemin relative vers l'image ppm à ouvrir.
\end{itemize}
\subsection{Autres}
D'autre cible make sont aussi disponible.
\begin{itemize}
    \item \$make clean, permet de supprimer les binaires géneré par la compilation
    \item \$make doc, permet de génerer la documentation doxygen sous format html ou latex, ils apparaîtront dans le répertoire du même nom
    
\end{itemize}

\section{Présentation de l'algorithme}
Le run-length encoding, appelé en français le codage par plages,
est un algorithme de compression de données sans perte en informatique. \\
Par exemple, considérant la séquence suivant:\\
WWWWWWWWWWWWBWWWWWWWWWWWWWWBBBWWW\\WWWWWWWWWWWWWWWWWWWWBWWWWWWWWWWW\\
Après compression, donneras le résultats suivant:\\
12W1B14W3B23W1B11W\\
Le premier remarque qu'on peut faire sur cet algorithme est qu'il dépend fortement de la présence ou non de 
répetition sur une même ligne, par exemple pour l'exemple qui suit:\\
WBWBWBWBWB\\
La compression donne ce resultat:\\
1W1B1W1B1W1B1W1B1W1B\\
A la fin, la taille du fichier a doublé, il existe donc une version qui gère mieux ce problème 
qu'on appel la méthode SGI, le même exemple donneras alors:\\
-10WBWBWBWBWB\\
S'il y a un long motif de non répetition, le compteur se désincremente pour signifier pour les N caractères qui suivent, 
ils seront différent.\\
Le fichier après compression est toujours plus grand que l'original, d'ailleurs, la taille post-compression n'est pas garantie à être plus petite, cependant, si on applique l'algorithme à une plus grande échelle, 
on peut espèrer obtenir un ratio de compression inférieur à 1 (La formule utilisée est Taille post-compression / Taille pré-compression).

\section{Présentation du code}
Une documentation existe pour ce projet, je ne vais donc pas vous présenter toutes les fonctions, car en réalité, nombreux sont les fonctions qui 
s'occupent de l'allocation mémoire plutôt que l'algorithme en lui même.
\subsection{main.c \& ppm.c}
Fichiers de base donnée par M.Bourdin, ils permettent de lire et d'afficher une image .ppm

\subsection{compress.h  \& ima.h}
Ces sont les headers utilisés pour ce projet, je vais donc vous présenter les différentes structure qui y sont déclarées.
\subsubsection{Image}
\begin{verbatim}
    struct Image {
        unsigned long sizeX;
        unsigned long sizeY;
        GLubyte *data;
    };
    typedef struct Image Image;        
\end{verbatim}
Image est la structure de base d'une image sous format RGB, il y a donc 3 informations, les 2 premières sont les dimensions de l'image, 
enfin, la dernière est un tableau de donnée linéaire de type GLubyte, les champs Rouge, Vert et Bleu sont mélangés entre eux, 
il faut donc effectuer une petite gymnatique d'esprit pour obtenir la valeur d'une pixel.\\
Il faut lire ce vecteur par paquet de trio, chaque trio étant constitué des valeurs R, G et B.

\subsubsection{Image\_RGB\_compressed}
\begin{verbatim}
    struct Image_RGB_compressed{
        unsigned long sizeX;
        unsigned long sizeY;
        unsigned long * ChannelSize;
        GLubyte **data;
    };
    typedef struct Image_RGB_compressed Image_RGB_compressed;
\end{verbatim}
Image\_RGB\_compressed est la structure d'image compressée sous format RGB, nous avons toujours nos champs sizeX et sizeY. 
Un nouveau champs ChannelSize est disponible, c'est un tableau qui contient la taille des 3 champs R, G et B.\\
Enfin data est devenu GLubyte ** data, car j'ai décidé de séparer les 3 champs de couleurs. \\
J'ai aussi choisis une representation dynamique par l'intermédiaire de pointer, même si pour ce projet, si on reste sur nos 3 champs RGB, il est plus économique de 
déclarer directement 3 GLubyte *, et 3 unsigned long car nous n'avons pas besoin de pointer additionnel. Néaumoins, il est toujours possible au projet d'évoluer au cours du temps, 
et d'avoir par exemple 4 voir 5 champs de données au lieu de 3.

\subsubsection{Image\_HSV}
\begin{verbatim}
    struct Image_HSV{
        unsigned long sizeX;
        unsigned long sizeY;
        GLshort * Hdata;
        GLubyte **SVdata;
    };
    typedef struct Image_HSV Image_HSV;
\end{verbatim}
Image\_HSV est la structure de base d'une image sous format HSV, il y a toujours les dimensions sizeX et sizeY. 
les champs S et V sont regroupé via un deuxième tableau SVdata. le champs H a été séparé des 2 autres car étant donné qu'il doit stocker une valeurs comprise entre 0 et 360,
le type GLubyte n'est plus suffisante([0:255] sur 1 octet), il faut donc prendre un GLshort à la place([-43767:43767] sur 2 octet).\\
Ce octet en plus est aussi la raison pourquoi notre implémentation HSV est plus lourde que RGB.

\subsubsection{Image\_HSV\_compressed}
\begin{verbatim}
    struct Image_HSV_compressed{
        unsigned long sizeX;
        unsigned long sizeY;
        unsigned long * ChannelSize;
        GLshort * Hdata;
        GLubyte **SVdata;
    };
    typedef struct Image_HSV_compressed Image_HSV_compressed;
\end{verbatim}
Image\_HSV\_compressed est la structure d'image compressé sous format HSV, il n'est pas très différente de Image\_HSV, car il y a 
juste un champs ChannelSize en plus. Ayant déja fini le projet à la rédaction de ce rapport, Image\_HSV n'est pas très utile en réalité, 
car sa fonctionalité est entièrement recouverte par Image\_HSV\_compressed, ce qui m'aurait 
permis d'éviter d'écrire les fonctions de conversion de Image\_HSV vers Image\_HSV\_compressed.

\section{compress.c}
Globalement nous pouvons diviser ce fichier en 2 parties, la première est consacrée à la compression sous format RGB, 
la seconde à la compression sous format HSV.
\subsection{Compression RGB}
Pour utilisateur, il n'a pas besoin de connaître les détails de l'implémentation car la compression est encapsulée via la fonction \\
\textit{create\_compressed\_image\_from\_RGB()}\\
Il suffit passer en paramètre de la fonction l'adresse de l'image source, ainsi que l'adresse de l'image\_RGB\_compressed.\\
Nous allons donc prendre le point de vue de l'utilisateur et descendre petit à petit dans le programme.
\subsubsection{create\_compressed\_image\_from\_RGB}
\begin{verbatim}
int create_compressed_image_from_RGB(Image *img,
                            Image_RGB_compressed *result){
  result->sizeX = img->sizeX;
  result->sizeY = img->sizeY;
  result->data = malloc( 3 * sizeof( unsigned long) );
  assert(result->data);
  result->ChannelSize = malloc( 3 * sizeof( GLubyte *));
  assert(result->ChannelSize);
  result->ChannelSize[RED] = compress_RGB(*img, result, RED);
  result->ChannelSize[GREEN]=compress_RGB(*img, result, GREEN);
  result->ChannelSize[BLUE] = compress_RGB(*img, result, BLUE);
  //printf_compressed_img(*result);
  return 1;
  }
\end{verbatim}
La fonction est très simple, tout d'abord, sauvegarder les dimensions original sizeX et sizeY, 
puis 2 malloc pour avoir le tableau des tailles post-compression ainsi que le pointeur vers les 3 champs de données.

\subsubsection{compress\_RGB}
La fonction alloue la mémoire et fait appel à \textit{compress\_GLubyte} qui va effectuer une première compression 
que j'appel "brute" car cela correspond à la première version de RLE que je vous ai présenté, par exemple, le pixel 
\textbf{[200, 120, 140]} deviendra \textbf{[[1, 200], [1, 120], [1, 140]]}\\
Enfin, la fonction \textit{reduce\_raw\_compressed} effectue une deuxième compression selon la méthode SGI pour avoir tableau de donnée plus compacte.

\subsubsection{compress\_GLubyte}
\begin{Verbatim}[numbers=left,xleftmargin = 5mm]

    unsigned long compress_GLubyte(GLubyte * data, GLbyte * storage, int type, 
                    unsigned long size, unsigned long img_step){
        GLubyte buffer = data[type];
        GLbyte counter =0;
        unsigned long k = 0;
        for (unsigned long i = type; i < size * img_step; i+=img_step){
            if(buffer == data[i]){
                if(counter < 127){
                    counter++;
                }else{
                    storage[k++] = counter; 
                    storage[k++] = buffer;
                    counter = 1;
                }
            }else{
                storage[k++] = counter; 
                storage[k++] = buffer;
                counter = 1;
                buffer = data[i];
            }
        }
        storage[k++] = counter; 
        storage[k++] = buffer;
        return k;
    }
\end{Verbatim}
Il y a beaucoup de paramètre à cette fonction car je m'en sert dans les 2 format de compression, car il permet de compresser des GLubyte comme son nom l'indique. En paramètre donc:
\begin{itemize}
    \item \textbf{data} et \textbf{storage} sont les tableaux de données source et de destination
    \item \textbf{type} indique le type de champs à lire, il peut s'agir d'un des 3 champs RGB ou des champs S ou V pour le format HSV.
    Plus concrétement, il donne l'emplacement de la tête de lecture.
    \item \textbf{size} est la taille du tableau data.
    \item \textbf{img\_step} est le pas de lecture à effectuer à chaque tour de boucle, pour le format RGB, il faut faire un saut de 3 à chaque fois, pour le format HSV, 1 seul pas suffit comme les données ne sont pas mélangées.
\end{itemize}
On itère donc sur le tableau data via le tampon de lecture de donnée \textbf{buffer}\\
ligne 8, si la valeur lue \textbf{data[i]} est identique à notre buffer,
2 cas se présente, soit le compteur est inférieur à 127, 
nous pouvons incrémenter compteur et passer à la valeur suivante. 
Sinon la valeur maximal du compteur est déja atteinte,
il faut alors sauvegarder le compteur et le buffer dans storage, 
puis mettre le compteur à 1 comme si le buffer avait changer.\\
Ligne 16, c'est le où la valeur lue \textbf{data[i]} est différente de notre \textbf{buffer}, il faut alors sauvegarder notre compteur et le buffer dans storage, remettre le compteur à 1 et enfin, changer la valeur du \textbf{buffer}.\\
Enfin, ligne 23-24 une dernière sauvegarde est effectué pour gérer la fin de lecture et le nombre de blocs utilisé \textbf{k} est retourné.

\subsubsection{reduce\_raw\_compressed}
\begin{Verbatim}[numbers=left,xleftmargin = 5mm]
GLbyte * reduce_raw_compressed(GLbyte* raw_compressed, unsigned long * size){
  GLbyte * result = malloc( *size * sizeof(GLbyte));
  assert(result);
  result[0] = 0;
  unsigned long empty_pt = 0, index_pt = 0;
  for (unsigned long i = 0; i < *size; i+=2){   
    if(raw_compressed[i] > maximum_repeat){
      index_pt = empty_pt++; 
      result[index_pt] = raw_compressed[i];
      result[empty_pt++] = raw_compressed[i+1];
    }
    else if(result[index_pt] < 0 
        && (result[index_pt] - raw_compressed[i] >= -127)){
      result[index_pt] -= raw_compressed[i];
      for (unsigned long j = 0; j < raw_compressed[i]; j++){
      result[empty_pt++] = raw_compressed[i+1];
      }    
    }else{
      index_pt = empty_pt++; 
      result[index_pt] = raw_compressed[i] * -1; 
      for (unsigned long j = 0; j < raw_compressed[i]; j++){
        result[empty_pt++] = raw_compressed[i+1];
      }
    }  
  }
  free(raw_compressed);
  *size = empty_pt; 
  return result;  
}
\end{Verbatim}
Cette fonction prend le relai de compress\_GLubyte, la boucle for itère avec un pas de 2, ce qui permet d'avoir seulement les cases de compteur.\\
Tout d'abord un nouveau tableau est alloué afin de stocker le resultat de la réduction.\\
Il y a donc 3 cas possible, La première ligne 7 est le cas où le compteur lue \textbf{raw\_compressed} est supérieur à \textbf{maximun\_repeat} (une variable global que j'ai décidé à 2, tout à fait modulable selon le besoin).\\
Imaginons que \textbf{raw\_compressed[i]} vaut 10, il y a une succession de 10 valeurs, 
\begin{math}10 > 2\end{math}, on sauvegarde le compteur \textbf{raw\_compressed[i]} 
et la valeur associé \textbf{raw\_compressed[i+1]}.\\
Ligne 12, arriver à cette ligne, nous sommes dans le cas où le compteur est inférieur à \textbf{maximun\_repeat},
2 cas peuvent se présenter, la première étant qu'il existe déja une reduction en cours
\begin{math}
    \textbf{result[index\_pt] \textless 0}
\end{math}\\
Il faut alors vérifier si ajout du compteur lue feras déborder ou non notre compteur en cours(ligne13)\\
Si l'ajout est possible, alors on continue à désincrementer \textbf{result[index\_pt]}
et on rajoute à la fin du tableau résultat le nombre de valeur nécessaire.\\
Enfin, dans le dernier cas (ligne 18), nous sommes face soit à un nouveau compteur de reduction à 
initialiser soit notre ancien compteur de réduction a atteint sa valeur limite.

\break
A la fin nous obtenons notre image compressée sous format RGB. Il faut désormais sauvegarder notre image compressée. 
\subsection{Sauvegarde RGB}
La fonction \textit{save\_compressed\_RGB\_image()} permet de réaliser cette tâche, il n'est pas très différente de \textit{ImageLoad()} du fichier \textbf{ppm.c}
\subsubsection{save\_compressed\_RGB\_image()}

\begin{Verbatim}[numbers=left,xleftmargin = 5mm]
  //image format
  fprintf(fp, "P7\n");
  ... écriture du header identique à ImageLoad() ... 

  // channelSize 
  fprintf(fp, "%lu %lu %lu\n", img->ChannelSize[RED], img->ChannelSize[GREEN], 
                                            img->ChannelSize[BLUE]);
    
  // pixel data
  for (size_t i = 0; i < 3; i++){
    if( (c = fwrite(img->data[i], (size_t) 1, (size_t) img->ChannelSize[i], fp))
                                                 != img->ChannelSize[i]){
      fprintf(stderr, "Failed to write data\n");
        exit(1);
    }
    printf("wrote c : %ld  | expected : %ld\n", c, img->ChannelSize[i]);
}
\end{Verbatim}
Pas de grande nouveauté, indicateur de format vaut \textbf{P7} au lieu de 
\textbf{P6} chez un fichier ppm classique. En plus des autres indicateurs, il faut ajouter 
aussi les valeurs de \textbf{ChannelSize} (ligne 6).\\
Enfin écriture des données se fait via le boucle for, les 3 champs ne sont pas mélangés, ils sont écrites dans l'ordre RGB.\\
Si le nombre de blocs écrite ne correspond pas à la taille attendu, une erreur est affiché et le programme fait un exit(1).

\subsection{Conversion RGB - HSV}
Pour les formules de conversion RGB - HSV ou HSV - RGB, j'ai utilisé les formules du site RapidTables, voici les liens:\\
\url{https://www.rapidtables.com/convert/color/rgb-to-hsv.html}\\
\url{https://www.rapidtables.com/convert/color/hsv-to-rgb.html}

\subsubsection{conv\_RGB\_img\_to\_HSV\_img}
Cette fonction permet d'allouer la mémoire pour les data de l'image HSV, puis fait appel à 
\textit{conv\_RGB\_HSV} qui va lire à chaque tour de boucle un trio RGB, calculer les valeurs HSV et les stocker dans l'image resultante.\\
Il est utile de noter que si pour la compression RGB, l'image est garantie sans perte, ce n'est pas pour le cas pour la compression HSV, 
cela est due à la perte d'information lors de la conversion. 
En effet, pour le format HSV, nous utilisons que des entiers naturel, \textbf{[0-360] pour H}, 
\textbf{[0-100] pour SV}, or, la plupart des données ont une precision après la virgule, malgré l'arrondi effectué dans 
nos calcule, il faut attendre à une différence de +-5 entre la valeur initial et la valeur converti.

\subsection{Compression HSV}
Après la conversion, nous avons une image HSV prête à être compressé, le schéma de fonctionnement est identique à celui d'une compression 
RGB.
\begin{itemize}
    \item create\_compressed\_image\_from\_HSV 
    \item compress\_H \& compress\_SV
    \item compress\_GLubyte $|$  compress\_GLshort
    \item reduce\_raw\_compressed\_hue $|$ reduce\_raw\_compressed
\end{itemize}
Les fonctions étant très similaire à celui d'une compression RGB, je ne vais pas vous les détailler pour une seconde fois.

\subsection{Sauvegarde HSV}
\subsubsection{save\_compressed\_HSV\_image}
\begin{Verbatim}[numbers=left,xleftmargin = 5mm]
void save_compressed_HSV_image(char * filename, Image_HSV_compressed * img){
    //image format
    fprintf(fp, "P8\n");
        ...
    unsigned long c;
    // channelSize // pixel data
    fprintf(fp, "%lu %lu %lu\n", img->ChannelSize[S], img->ChannelSize[V],
             img->ChannelSize[H]);
    
    if((c = fwrite(img->SVdata[S], (size_t) 1, (size_t) img->ChannelSize[S], fp)) 
                                            != img->ChannelSize[S]){
        fprintf(stderr, "Failed to write data\n");
        exit(1);
    }
    printf("wrote S : %ld  | expected : %ld\n", c, img->ChannelSize[S]);
    
    if((c = fwrite(img->SVdata[V], (size_t) 1, (size_t) img->ChannelSize[V], fp)) 
                                            != img->ChannelSize[V]){
        fprintf(stderr, "Failed to write data\n");
        exit(1);
    }
    printf("wrote V : %ld  | expected : %ld\n", c, img->ChannelSize[V]);
    
    if((c = fwrite(img->Hdata, (size_t) sizeof(GLshort), (size_t) 
        img->ChannelSize[H], fp)) != img->ChannelSize[H]){
        fprintf(stderr, "Failed to write data\n");
        exit(1);
    }
    printf("wrote H : %ld  | expected : %ld\n", c, img->ChannelSize[H]);
    fclose(fp);
}
\end{Verbatim}
Le header ne change pas sauf le passage au format \textbf{P8}, ligne 7, écriture des tailles compressées.\\
Ligne 10,17,25 écriture des données HSV via fwrite. Un contrôle est effectué pour s'assurer que le nombre de blocs écrite est correct.

\subsection{Lecture et décompression RGB}
La lecture et la décompression RGB se fait via la fonction \textit{Image\_load}, il s'agit d'une fonction que j'ai modifié en se basant sur la 
fonction \textit{ImageLoad\_PPM} du fichier \textbf{ppm.c}
\subsubsection{Image\_load}
\begin{Verbatim}[numbers=left,xleftmargin = 5mm]
int Image_load(char *filename, Image *img){
...
}else if(buff[1] == '7'){
    Image_RGB_compressed img_comp;
    img_comp.sizeX = img->sizeX;
    img_comp.sizeY = img->sizeY;
    img_comp.ChannelSize = malloc(3 * sizeof(unsigned long));
    img_comp.data = malloc(3 * sizeof(GLubyte*));

    if (fscanf(fp, "%lu %lu %lu\n", &img_comp.ChannelSize[RED], 
            &img_comp.ChannelSize[GREEN], &img_comp.ChannelSize[BLUE]) != 3){
      fprintf(stderr, "Invalid image size (error loading '%s')\n", filename);
      exit(1);
    }
    
    for (size_t i = 0; i < 3; i++){
      img_comp.data[i] = malloc(img_comp.ChannelSize[i] * sizeof(GLubyte));

      if((r = fread(img_comp.data[i], (size_t)1, 
          (size_t)img_comp.ChannelSize[i], fp)) 
                      != img_comp.ChannelSize[i] ){
          fprintf(stderr,"Failed to read data");
          exit(1);
      }
      printf("Blocs read = %lu | expected %lu\n",r, img_comp.ChannelSize[i]);
    }
    
    decompress_RGB(&img_comp, img);
}
...
}
\end{Verbatim}
S'il la fonction rencontre le header \textbf{P7}, il est face un fichier compressé RGB, donc il faut d'abord
un \textit{fscanf} pour lire la taille des \textbf{ChannelSize} (ligne 10)\\
Puis un boucle for est utilisé pour lire les champs RGB (ligne 16).\\
Enfin la fonction \textit{decompress\_RGB} est appelé pour decompresser l'image.

\subsubsection{decompress\_RGB}
\begin{Verbatim}[numbers=left,xleftmargin = 5mm]
void decompress_RGB(Image_RGB_compressed *img, Image * result){
  result->sizeX = img->sizeX;
  result->sizeY = img->sizeY;
  //printf(">channels size: %lu %lu %lu\n", img->ChannelSize[RED],
           img->ChannelSize[GREEN], img->ChannelSize[BLUE]);
  result->data = malloc( result->sizeX * result->sizeY * 3 * sizeof(GLubyte));
  assert(result->data);

  for (int i = 0; i < 3; i++){
    decompress_GLubytes(img->data[i], result->data, img->ChannelSize[i], i, 3);    
  }
}
\end{Verbatim}


\subsubsection{decompress\_GLubyte}
\begin{Verbatim}[numbers=left,xleftmargin = 5mm]
void decompress_GLubytes(GLubyte * src, GLubyte * dst, unsigned long size_src, 
                                                int pos, int coeff){
  unsigned long i = 0;
  GLbyte iter_buffer;
  GLubyte value_buffer;
  unsigned long size_counter = 0;
  while (i < size_src){
    iter_buffer = src[i];
    if(iter_buffer > 0){
      value_buffer = src[i+1];
      for (size_t k = 0; k < iter_buffer; k++){
        dst[size_counter++ * coeff + pos] = value_buffer;
      }
      i+=2;

    }else{ 
      iter_buffer = iter_buffer * -1;
      for (size_t k = 0; k < iter_buffer; k++){
        value_buffer = src[++i];
          dst[size_counter++ * coeff + pos] = value_buffer;
      }
        i++;               
    }
  }
}
\end{Verbatim}
La décompression est très simple, tant que i



%\begin{figure}
%    \includegraphics[width=\linewidth]{img/L1.png}
%    \caption{Welcome page}
%    \label{fig:L1}
%\end{figure}

%\includegraphics[width=\linewidth]{img/L6.png}
 
\end{document}

